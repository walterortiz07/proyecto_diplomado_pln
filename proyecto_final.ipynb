{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mmaguero/diploma_fpuna_nlp_ia/blob/master/2025/final_project_guide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBszMmZg6LlU"
   },
   "source": [
    "# Preparación y unificación del Diccionario Guaraní-Español y Español-Guaraní para Fine-tuning\n",
    "\n",
    "En esta sección se procesan los diccionarios estructurados de ambos sentidos (español-guaraní y guaraní-español) y se unifican en un solo archivo para su uso en tareas de PLN y entrenamiento de modelos. No se generan archivos intermedios, solo el archivo final unificado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEiZQ-s-HFix"
   },
   "source": [
    "Repositorio de este proyecto:\n",
    "https://github.com/walterortiz07/proyecto_diplomado_pln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalamos las librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\walte\\miniconda3\\envs\\python_env\\lib\\site-packages (0.11.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\walte\\miniconda3\\envs\\python_env\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\walte\\miniconda3\\envs\\python_env\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pdfminer.six==20251107 in c:\\users\\walte\\miniconda3\\envs\\python_env\\lib\\site-packages (from pdfplumber) (20251107)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\walte\\miniconda3\\envs\\python_env\\lib\\site-packages (from pdfplumber) (11.3.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\walte\\miniconda3\\envs\\python_env\\lib\\site-packages (from pdfplumber) (5.2.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\walte\\miniconda3\\envs\\python_env\\lib\\site-packages (from pdfminer.six==20251107->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\walte\\miniconda3\\envs\\python_env\\lib\\site-packages (from pdfminer.six==20251107->pdfplumber) (46.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\walte\\miniconda3\\envs\\python_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\walte\\miniconda3\\envs\\python_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\walte\\miniconda3\\envs\\python_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\walte\\miniconda3\\envs\\python_env\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\walte\\miniconda3\\envs\\python_env\\lib\\site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\walte\\miniconda3\\envs\\python_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber pandas numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwKUas8OMgbY"
   },
   "source": [
    "Importamos las librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1I0OvDV0TTBU"
   },
   "outputs": [],
   "source": [
    "## Para datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "## Para gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pdfplumber\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ssfm-PuV65F"
   },
   "source": [
    "Abrimos el data-set como un dataframe: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
    "\n",
    "Entrada: Identificador del archivo.\n",
    "\n",
    "Salida: Una tabla DataFrame de Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fontnames únicos y su frecuencia:\n",
      "UNPVBK+ArialMT: 8096\n",
      "QMVCXS+Arial-BoldMT: 3921\n",
      "CJUWJU+Arial-BoldMT: 639\n",
      "VEGBPI+ArialMT: 344\n",
      "ZUIJTA+Alegreya-Regular: 73\n",
      "TEBKNM+SuezOne-Regular: 3\n",
      "UDQQBK+SuezOne-Regular: 2\n"
     ]
    }
   ],
   "source": [
    "# Inspeccionar fontnames únicos en las páginas relevantes para detectar negrita\n",
    "pdf_path = 'Diccionario Guaraní-Español Español-Guaraní.pdf'\n",
    "from collections import Counter\n",
    "\n",
    "def print_unique_fontnames(pdf_path, start_page, end_page):\n",
    "    fontnames = Counter()\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i in range(start_page-1, end_page):\n",
    "            page = pdf.pages[i]\n",
    "            words = page.extract_words(use_text_flow=True, keep_blank_chars=True, extra_attrs=[\"fontname\"])\n",
    "            for w in words:\n",
    "                fontnames[w.get('fontname', 'None')] += 1\n",
    "    print('Fontnames únicos y su frecuencia:')\n",
    "    for font, count in fontnames.most_common():\n",
    "        print(f'{font}: {count}')\n",
    "\n",
    "# Cambia el rango según el diccionario que quieras analizar\n",
    "print_unique_fontnames(pdf_path, 13, 85)  # Prueba con las primeras páginas del diccionario Guaraní-Español"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción paso a paso del diccionario a CSV\n",
    "A continuación, se muestra el proceso detallado y dividido en celdas para extraer las entradas del diccionario desde el PDF, construir el DataFrame y guardar los archivos CSV. El resultado final será idéntico al método anterior, pero cada paso será explicado y ejecutado por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras extraídas Guaraní-Español: 13000\n",
      "Palabras extraídas Español-Guaraní: 20548\n"
     ]
    }
   ],
   "source": [
    "# 1. Extraer palabras y atributos de las páginas relevantes del PDF\n",
    "\n",
    "def extract_words_with_attrs(pdf_path, start_page, end_page):\n",
    "    all_words = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i in range(start_page-1, end_page):\n",
    "            page = pdf.pages[i]\n",
    "            width = page.width\n",
    "            height = page.height\n",
    "            mid = width / 2\n",
    "            for col_idx, bbox in enumerate([(0, 0, mid, height), (mid, 0, width, height)]):\n",
    "                col = page.within_bbox(bbox)\n",
    "                if not col:\n",
    "                    continue\n",
    "                words = col.extract_words(use_text_flow=True, keep_blank_chars=True, extra_attrs=[\"fontname\", \"top\"])\n",
    "                words = [dict(w, page=i+1, col=col_idx+1) for w in words if not re.fullmatch(r'\\d+', w[\"text\"])]\n",
    "                all_words.extend(words)\n",
    "    return all_words\n",
    "\n",
    "# Ejemplo: extraer palabras del diccionario Guaraní-Español (páginas 13 a 85)\n",
    "words_guarani_espanol = extract_words_with_attrs(pdf_path, 13, 85)\n",
    "# Y del diccionario Español-Guaraní (páginas 87 a 213)\n",
    "words_espanol_guarani = extract_words_with_attrs(pdf_path, 87, 213)\n",
    "\n",
    "print(f\"Palabras extraídas Guaraní-Español: {len(words_guarani_espanol)}\")\n",
    "print(f\"Palabras extraídas Español-Guaraní: {len(words_espanol_guarani)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 2: Detectar inicios de línea y marcar palabras iniciales y negrita\n",
    "\n",
    "Ahora, para cada columna, detectamos los saltos de línea (por cambios en la coordenada 'top') y marcamos qué palabras son iniciales y cuáles están en negrita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>top</th>\n",
       "      <th>doctop</th>\n",
       "      <th>bottom</th>\n",
       "      <th>upright</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>direction</th>\n",
       "      <th>fontname</th>\n",
       "      <th>page</th>\n",
       "      <th>col</th>\n",
       "      <th>is_bold</th>\n",
       "      <th>is_initial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a.</td>\n",
       "      <td>56.6929</td>\n",
       "      <td>65.9769</td>\n",
       "      <td>181.6169</td>\n",
       "      <td>10284.2969</td>\n",
       "      <td>192.6169</td>\n",
       "      <td>True</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.2840</td>\n",
       "      <td>ltr</td>\n",
       "      <td>QMVCXS+Arial-BoldMT</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vocal que se pronuncia igual que en español.</td>\n",
       "      <td>65.9756</td>\n",
       "      <td>293.6382</td>\n",
       "      <td>181.0559</td>\n",
       "      <td>10283.7359</td>\n",
       "      <td>192.0559</td>\n",
       "      <td>True</td>\n",
       "      <td>11.0</td>\n",
       "      <td>227.6626</td>\n",
       "      <td>ltr</td>\n",
       "      <td>UNPVBK+ArialMT</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2. Pref. a. v. de 1ª. Per. sin. para verbos pr...</td>\n",
       "      <td>56.6929</td>\n",
       "      <td>290.5298</td>\n",
       "      <td>194.2560</td>\n",
       "      <td>10296.9360</td>\n",
       "      <td>205.2560</td>\n",
       "      <td>True</td>\n",
       "      <td>11.0</td>\n",
       "      <td>233.8369</td>\n",
       "      <td>ltr</td>\n",
       "      <td>UNPVBK+ArialMT</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ã.</td>\n",
       "      <td>56.6929</td>\n",
       "      <td>65.9775</td>\n",
       "      <td>213.6862</td>\n",
       "      <td>10316.3662</td>\n",
       "      <td>224.6862</td>\n",
       "      <td>True</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.2846</td>\n",
       "      <td>ltr</td>\n",
       "      <td>QMVCXS+Arial-BoldMT</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vocal que se pronuncia igual que la</td>\n",
       "      <td>65.9756</td>\n",
       "      <td>257.2546</td>\n",
       "      <td>213.1252</td>\n",
       "      <td>10315.8052</td>\n",
       "      <td>224.1252</td>\n",
       "      <td>True</td>\n",
       "      <td>11.0</td>\n",
       "      <td>191.2790</td>\n",
       "      <td>ltr</td>\n",
       "      <td>UNPVBK+ArialMT</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       x0        x1  \\\n",
       "0                                                 a.  56.6929   65.9769   \n",
       "1      Vocal que se pronuncia igual que en español.   65.9756  293.6382   \n",
       "2  2. Pref. a. v. de 1ª. Per. sin. para verbos pr...  56.6929  290.5298   \n",
       "3                                                 ã.  56.6929   65.9775   \n",
       "4               Vocal que se pronuncia igual que la   65.9756  257.2546   \n",
       "\n",
       "        top      doctop    bottom  upright  height     width direction  \\\n",
       "0  181.6169  10284.2969  192.6169     True    11.0    9.2840       ltr   \n",
       "1  181.0559  10283.7359  192.0559     True    11.0  227.6626       ltr   \n",
       "2  194.2560  10296.9360  205.2560     True    11.0  233.8369       ltr   \n",
       "3  213.6862  10316.3662  224.6862     True    11.0    9.2846       ltr   \n",
       "4  213.1252  10315.8052  224.1252     True    11.0  191.2790       ltr   \n",
       "\n",
       "              fontname  page  col  is_bold  is_initial  \n",
       "0  QMVCXS+Arial-BoldMT    13    1     True        True  \n",
       "1       UNPVBK+ArialMT    13    1    False       False  \n",
       "2       UNPVBK+ArialMT    13    1    False        True  \n",
       "3  QMVCXS+Arial-BoldMT    13    1     True        True  \n",
       "4       UNPVBK+ArialMT    13    1    False       False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Marcar palabras iniciales y negrita en cada columna\n",
    "\n",
    "def mark_initial_and_bold(words):\n",
    "    df = pd.DataFrame(words)\n",
    "    df['is_bold'] = df['fontname'].apply(lambda f: f is not None and f.endswith('Arial-BoldMT'))\n",
    "    df['is_initial'] = False\n",
    "    for (page, col), group in df.groupby(['page', 'col']):\n",
    "        tops = group['top'].values\n",
    "        idxs = group.index.values\n",
    "        line_starts = [0]\n",
    "        threshold = 3\n",
    "        for j in range(1, len(tops)):\n",
    "            if abs(tops[j] - tops[j-1]) > threshold:\n",
    "                line_starts.append(j)\n",
    "        df.loc[idxs[line_starts], 'is_initial'] = True\n",
    "    return df\n",
    "\n",
    "df_guarani_espanol = mark_initial_and_bold(words_guarani_espanol)\n",
    "df_espanol_guarani = mark_initial_and_bold(words_espanol_guarani)\n",
    "\n",
    "df_guarani_espanol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 3: Reconstruir las entradas (headword y traducción) a partir de las palabras marcadas\n",
    "\n",
    "Ahora, reconstruimos cada entrada del diccionario: solo cuando una palabra es inicial y negrita, se inicia una nueva entrada; el resto se concatena según las reglas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palabra</th>\n",
       "      <th>traduccion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>Vocal que se pronuncia igual que en español.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ã</td>\n",
       "      <td>Vocal que se pronuncia igual que la  a  pero  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‘a</td>\n",
       "      <td>s. Fruto, fruta.  2. Caída.  3. Huevo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‘ã</td>\n",
       "      <td>s. Ausencia.  2. Abrigo.  3. Sombra.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ache</td>\n",
       "      <td>s.  Parcialidad indígena guaraní, guayaki.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  palabra                                         traduccion\n",
       "0       a  Vocal que se pronuncia igual que en español.  ...\n",
       "1       ã  Vocal que se pronuncia igual que la  a  pero  ...\n",
       "2      ‘a             s. Fruto, fruta.  2. Caída.  3. Huevo.\n",
       "3      ‘ã               s. Ausencia.  2. Abrigo.  3. Sombra.\n",
       "4    ache         s.  Parcialidad indígena guaraní, guayaki."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Reconstruir entradas: headword (palabra en negrita inicial) y traducción\n",
    "\n",
    "def build_entries(df):\n",
    "    entries = []\n",
    "    line = ''\n",
    "    bold_headword = None\n",
    "    for _, row in df.iterrows():\n",
    "        word = row['text']\n",
    "        is_initial = row['is_initial']\n",
    "        is_bold = row['is_bold']\n",
    "        if is_initial:\n",
    "            if is_bold:\n",
    "                if line.strip() and bold_headword:\n",
    "                    palabra = bold_headword.strip().rstrip('.')\n",
    "                    traduccion = line.strip()[len(bold_headword):].lstrip(' .:;-')\n",
    "                    entries.append({'palabra': palabra, 'traduccion': traduccion})\n",
    "                line = word\n",
    "                bold_headword = word\n",
    "            else:\n",
    "                if line.strip():\n",
    "                    line += ' ' + word\n",
    "                else:\n",
    "                    line = word\n",
    "        else:\n",
    "            line += ' ' + word\n",
    "    if line.strip() and bold_headword:\n",
    "        palabra = bold_headword.strip().rstrip('.')\n",
    "        traduccion = line.strip()[len(bold_headword):].lstrip(' .:;-')\n",
    "        entries.append({'palabra': palabra, 'traduccion': traduccion})\n",
    "    return pd.DataFrame(entries)\n",
    "\n",
    "# Aplicar a ambos diccionarios\n",
    "df_entries_guarani_espanol = build_entries(df_guarani_espanol)\n",
    "df_entries_espanol_guarani = build_entries(df_espanol_guarani)\n",
    "\n",
    "df_entries_guarani_espanol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 4: Creamos la carpeta archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpeta \"archivos\" lista para guardar el archivo final unificado.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Asegurar la existencia de la carpeta donde se guardará el archivo final unificado\n",
    "os.makedirs('archivos', exist_ok=True)\n",
    "print('Carpeta \"archivos\" lista para guardar el archivo final unificado.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo estructurado guardado: archivos/diccionario_guarani_espanol_estructurado.tsv\n",
      "Archivo estructurado guardado: archivos/diccionario_espanol_guarani_estructurado.tsv\n",
      "Ejemplo guaraní-español:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palabra_guarani</th>\n",
       "      <th>tipo_etiqueta</th>\n",
       "      <th>categoria_gramatical</th>\n",
       "      <th>traduccion_limpia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>añete</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9396</th>\n",
       "      <td>rory</td>\n",
       "      <td></td>\n",
       "      <td>f</td>\n",
       "      <td>eliz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10740</th>\n",
       "      <td>tembiguái</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>siervo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>jeroviaukaha</td>\n",
       "      <td></td>\n",
       "      <td>s. ra</td>\n",
       "      <td>Garante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6809</th>\n",
       "      <td>ñemondýi</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>susto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>avati’y</td>\n",
       "      <td></td>\n",
       "      <td>m</td>\n",
       "      <td>espiga de aíz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>aña</td>\n",
       "      <td></td>\n",
       "      <td>s.</td>\n",
       "      <td>Diablo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6807</th>\n",
       "      <td>ñemondýi</td>\n",
       "      <td></td>\n",
       "      <td>s.</td>\n",
       "      <td>Espanto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11579</th>\n",
       "      <td>tymba’api</td>\n",
       "      <td></td>\n",
       "      <td>s.</td>\n",
       "      <td>Caza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7354</th>\n",
       "      <td>ogaygua</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pariente</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      palabra_guarani tipo_etiqueta categoria_gramatical traduccion_limpia\n",
       "326             añete                                                 real\n",
       "9396             rory                                  f              eliz\n",
       "10740       tembiguái                                               siervo\n",
       "3493     jeroviaukaha                              s. ra           Garante\n",
       "6809         ñemondýi                                                susto\n",
       "799           avati’y                                  m     espiga de aíz\n",
       "318               aña                                 s.            Diablo\n",
       "6807         ñemondýi                                 s.           Espanto\n",
       "11579       tymba’api                                 s.              Caza\n",
       "7354          ogaygua                                             pariente"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo español-guaraní:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palabra_espanol</th>\n",
       "      <th>tipo_etiqueta</th>\n",
       "      <th>categoria_gramatical</th>\n",
       "      <th>traduccion_limpia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>encabezar</td>\n",
       "      <td></td>\n",
       "      <td>m</td>\n",
       "      <td>yakã</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5403</th>\n",
       "      <td>femenino, na</td>\n",
       "      <td></td>\n",
       "      <td>adj.</td>\n",
       "      <td>Kuña rehegua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6650</th>\n",
       "      <td>iguana</td>\n",
       "      <td></td>\n",
       "      <td>f.</td>\n",
       "      <td>Teju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>caprichoso, sa</td>\n",
       "      <td></td>\n",
       "      <td>adj. va</td>\n",
       "      <td>Aváva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6828</th>\n",
       "      <td>incendiar</td>\n",
       "      <td></td>\n",
       "      <td>tr.</td>\n",
       "      <td>Hapy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11620</th>\n",
       "      <td>profundizar</td>\n",
       "      <td></td>\n",
       "      <td>tr.</td>\n",
       "      <td>Mbopypuku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10912</th>\n",
       "      <td>pique</td>\n",
       "      <td></td>\n",
       "      <td>m.</td>\n",
       "      <td>Tũ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>burlar</td>\n",
       "      <td></td>\n",
       "      <td>tr. m</td>\n",
       "      <td>Ñembohory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>barco</td>\n",
       "      <td></td>\n",
       "      <td>ra ta.</td>\n",
       "      <td>yga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>fallecer</td>\n",
       "      <td></td>\n",
       "      <td>intr.</td>\n",
       "      <td>Mano</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      palabra_espanol tipo_etiqueta categoria_gramatical traduccion_limpia\n",
       "4400        encabezar                                  m              yakã\n",
       "5403     femenino, na                               adj.      Kuña rehegua\n",
       "6650           iguana                                 f.              Teju\n",
       "1927   caprichoso, sa                            adj. va             Aváva\n",
       "6828        incendiar                                tr.              Hapy\n",
       "11620     profundizar                                tr.         Mbopypuku\n",
       "10912           pique                                 m.                Tũ\n",
       "1713           burlar                              tr. m         Ñembohory\n",
       "1455            barco                             ra ta.               yga\n",
       "5279         fallecer                              intr.              Mano"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Extracción robusta de todas las abreviaturas para ambos diccionarios (actualizado con nuevas abreviaturas y limpieza de numeraciones residuales) ---\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Listas de abreviaturas\n",
    "TIPOS_ETIQUETA = ['neol.', 'arc.', 'h.']\n",
    "CATEGORIAS_GRAMATICALES = [\n",
    "    'adj.', 'tr.', 'adv.', 'prep.', 's.', 'v.', 'participio pasivo', 'participio activo',\n",
    "    'verbo transitivo', 'verbo intransitivo', 'adjetivo', 'sustantivo', 'pron.', 'conj.', 'interj.',\n",
    "    'art.', 'num.', 'part.', 'pref.', 'suf.', 'f.', 'm.', 'ta.', 'Tr.', 'prnl.', 'ra.', 'com.', 'int.', 'va.',\n",
    "    'da.', 'intr.', 'sa.', 'y f.', 'm y f.', 'va.', 'intrans.', 'trans.', 'exp.', 'pl.', 'dem.', 'sing.', 'rel.', 'int.', 'com.', 'adj', 'intr', 'tr', 'f', 'm', 'ta', 'da', 'sa', 'va', 'ra', 'com', 'int', 'pl', 'dem', 'sing', 'rel', 'exp', 'prnl', 'intrans', 'trans', 'gram.',\n",
    "    # Nuevas abreviaturas encontradas:\n",
    "    'atr.', 'adv .', 'ind.', 'neg.', 'pr.'\n",
    "]\n",
    "# Unir ambas listas para búsqueda general\n",
    "ALL_ABBR = TIPOS_ETIQUETA + CATEGORIAS_GRAMATICALES\n",
    "# Ordenar por longitud descendente para evitar capturas parciales\n",
    "ALL_ABBR = sorted(set(ALL_ABBR), key=len, reverse=True)\n",
    "ABBR_REGEX = r'|'.join([re.escape(a) for a in ALL_ABBR])\n",
    "\n",
    "# Función robusta de extracción de todas las abreviaturas\n",
    "def extract_labels_and_clean(text):\n",
    "    # Buscar todas las abreviaturas en cualquier parte del texto\n",
    "    abbrs = re.findall(rf'({ABBR_REGEX})', text)\n",
    "    tipo_etiqueta = []\n",
    "    categoria_gramatical = []\n",
    "    for abbr in abbrs:\n",
    "        if abbr in TIPOS_ETIQUETA:\n",
    "            tipo_etiqueta.append(abbr)\n",
    "        elif abbr in CATEGORIAS_GRAMATICALES:\n",
    "            categoria_gramatical.append(abbr)\n",
    "    # Eliminar todas las abreviaturas encontradas del texto\n",
    "    for abbr in abbrs:\n",
    "        text = re.sub(rf'\\b{re.escape(abbr)}[\\s,.]*', '', text)\n",
    "    text = text.lstrip('. ').strip()\n",
    "    # Quitar punto final si existe\n",
    "    text = text.rstrip('.')\n",
    "    # Eliminar numeraciones residuales (ej: '2.', '3.', etc. al inicio o en medio)\n",
    "    text = re.sub(r'(\\b\\d+\\.)', '', text).strip()\n",
    "    # Eliminar espacios dobles generados\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return ' '.join(tipo_etiqueta), ' '.join(categoria_gramatical), text\n",
    "\n",
    "def split_and_expand(row, sentido):\n",
    "    if sentido == 'ge':\n",
    "        palabra_col = 'palabra' if 'palabra' in row else 'palabra_guarani'\n",
    "        palabra = row.get(palabra_col, '')\n",
    "    else:\n",
    "        palabra_col = 'palabra' if 'palabra' in row else 'palabra_espanol'\n",
    "        palabra = row.get(palabra_col, '')\n",
    "    output = str(row['traduccion']) if 'traduccion' in row else str(row.get('output', ''))\n",
    "    output = output if not pd.isnull(output) else ''\n",
    "    # Separar por número (2., 3., ...)\n",
    "    partes = re.split(r'(?<=\\.)\\s*(\\d+\\.)\\s*', output)\n",
    "    traducciones = []\n",
    "    if partes:\n",
    "        traducciones.append(partes[0].strip())\n",
    "        for i in range(1, len(partes), 2):\n",
    "            traducciones.append(partes[i+1].strip() if i+1 < len(partes) else '')\n",
    "    else:\n",
    "        traducciones = [output.strip()]\n",
    "    filas = []\n",
    "    for trad in traducciones:\n",
    "        subtrads = [t.strip() for t in trad.split(',') if t.strip()]\n",
    "        for subtrad in subtrads:\n",
    "            tipo_etiqueta, categoria_gramatical, subtrad_limpia = extract_labels_and_clean(subtrad)\n",
    "            if sentido == 'ge':\n",
    "                fila = {\n",
    "                    'palabra_guarani': palabra,\n",
    "                    'tipo_etiqueta': tipo_etiqueta,\n",
    "                    'categoria_gramatical': categoria_gramatical,\n",
    "                    'traduccion_limpia': subtrad_limpia\n",
    "                }\n",
    "            else:\n",
    "                fila = {\n",
    "                    'palabra_espanol': palabra,\n",
    "                    'tipo_etiqueta': tipo_etiqueta,\n",
    "                    'categoria_gramatical': categoria_gramatical,\n",
    "                    'traduccion_limpia': subtrad_limpia\n",
    "                }\n",
    "            filas.append(fila)\n",
    "    return filas\n",
    "\n",
    "# Procesar guaraní-español\n",
    "ge_expandidas = []\n",
    "for _, row in df_entries_guarani_espanol.iterrows():\n",
    "    ge_expandidas.extend(split_and_expand(row, 'ge'))\n",
    "df_estructurado_ge = pd.DataFrame(ge_expandidas)\n",
    "cols_ge = ['palabra_guarani', 'tipo_etiqueta', 'categoria_gramatical', 'traduccion_limpia']\n",
    "df_estructurado_ge = df_estructurado_ge[cols_ge]\n",
    "# Eliminar filas vacías en traduccion_limpia\n",
    "df_estructurado_ge = df_estructurado_ge[df_estructurado_ge['traduccion_limpia'].str.strip() != '']\n",
    "df_estructurado_ge.to_csv('archivos/diccionario_guarani_espanol_estructurado.tsv', sep='\\t', index=False, encoding='utf-8')\n",
    "print('Archivo estructurado guardado: archivos/diccionario_guarani_espanol_estructurado.tsv')\n",
    "\n",
    "# Procesar español-guaraní\n",
    "eg_expandidas = []\n",
    "for _, row in df_entries_espanol_guarani.iterrows():\n",
    "    eg_expandidas.extend(split_and_expand(row, 'eg'))\n",
    "df_estructurado_eg = pd.DataFrame(eg_expandidas)\n",
    "cols_eg = ['palabra_espanol', 'tipo_etiqueta', 'categoria_gramatical', 'traduccion_limpia']\n",
    "df_estructurado_eg = df_estructurado_eg[cols_eg]\n",
    "# Eliminar filas vacías en traduccion_limpia\n",
    "df_estructurado_eg = df_estructurado_eg[df_estructurado_eg['traduccion_limpia'].str.strip() != '']\n",
    "df_estructurado_eg.to_csv('archivos/diccionario_espanol_guarani_estructurado.tsv', sep='\\t', index=False, encoding='utf-8')\n",
    "print('Archivo estructurado guardado: archivos/diccionario_espanol_guarani_estructurado.tsv')\n",
    "\n",
    "from IPython.display import display\n",
    "print('Ejemplo guaraní-español:')\n",
    "display(df_estructurado_ge.sample(10))\n",
    "print('Ejemplo español-guaraní:')\n",
    "display(df_estructurado_eg.sample(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo de diccionario estructurado español-guaraní (una traducción por línea):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palabra_espanol</th>\n",
       "      <th>tipo_etiqueta</th>\n",
       "      <th>categoria_gramatical</th>\n",
       "      <th>traduccion_limpia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8149</th>\n",
       "      <td>saleroso, sa</td>\n",
       "      <td></td>\n",
       "      <td>adj.</td>\n",
       "      <td>Juky.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6475</th>\n",
       "      <td>perfidia</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>f. Nañangue.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>desteñir</td>\n",
       "      <td></td>\n",
       "      <td>tr.</td>\n",
       "      <td>Mboje’o.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>mimosa</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>f.  Jukeri, ka’aikove.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6630</th>\n",
       "      <td>pillo, lla</td>\n",
       "      <td></td>\n",
       "      <td>adj.</td>\n",
       "      <td>Ha’eve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8381</th>\n",
       "      <td>serranía</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>f. Yvytyrusu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>brutalidad</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Tajasu reko.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3223</th>\n",
       "      <td>famoso,</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sa.   adj.  Herakuã,  ojekuaháva  opavavére.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6460</th>\n",
       "      <td>perdonar</td>\n",
       "      <td></td>\n",
       "      <td>tr.</td>\n",
       "      <td>Ñyrõ, jora.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>fijar</td>\n",
       "      <td></td>\n",
       "      <td>tr.</td>\n",
       "      <td>Moĩ, jatyka, mombyta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     palabra_espanol tipo_etiqueta categoria_gramatical  \\\n",
       "8149    saleroso, sa                               adj.   \n",
       "6475        perfidia                                      \n",
       "2276        desteñir                                tr.   \n",
       "5395          mimosa                                      \n",
       "6630      pillo, lla                               adj.   \n",
       "8381        serranía                                      \n",
       "1003      brutalidad                                      \n",
       "3223         famoso,                                      \n",
       "6460        perdonar                                tr.   \n",
       "3311           fijar                                tr.   \n",
       "\n",
       "                                 traduccion_limpia  \n",
       "8149                                         Juky.  \n",
       "6475                                  f. Nañangue.  \n",
       "2276                                      Mboje’o.  \n",
       "5395                        f.  Jukeri, ka’aikove.  \n",
       "6630                                       Ha’eve.  \n",
       "8381                                 f. Yvytyrusu.  \n",
       "1003                                  Tajasu reko.  \n",
       "3223  sa.   adj.  Herakuã,  ojekuaháva  opavavére.  \n",
       "6460                                   Ñyrõ, jora.  \n",
       "3311                         Moĩ, jatyka, mombyta.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo estructurado guardado: archivos/diccionario_espanol_guarani_estructurado.tsv\n"
     ]
    }
   ],
   "source": [
    "# --- Normalización granular y desdoblamiento de traducciones múltiples (español-guaraní) ---\n",
    "def split_multiple_translations_eg(row):\n",
    "    \"\"\"\n",
    "    Divide las traducciones separadas por números (2. 3. 4. ...) en líneas independientes,\n",
    "    manteniendo la palabra_espanol y extrayendo tipo_etiqueta y categoria_gramatical para cada una.\n",
    "    \"\"\"\n",
    "    palabra = row['palabra'] if 'palabra' in row else row['palabra_espanol']\n",
    "    output = str(row['traduccion']) if 'traduccion' in row else str(row['output'])\n",
    "    output = output if not pd.isnull(output) else ''\n",
    "    partes = re.split(r'(?<=\\.)\\s*(\\d+\\.)\\s*', output)\n",
    "    traducciones = []\n",
    "    if partes:\n",
    "        traducciones.append(partes[0].strip())\n",
    "        for i in range(1, len(partes), 2):\n",
    "            traducciones.append(partes[i+1].strip() if i+1 < len(partes) else '')\n",
    "    else:\n",
    "        traducciones = [output.strip()]\n",
    "    filas = []\n",
    "    for trad in traducciones:\n",
    "        tipo_etiqueta = ''\n",
    "        tipo_match = re.match(r'^(neol\\.|arc\\.|h\\.)', trad)\n",
    "        if tipo_match:\n",
    "            tipo_etiqueta = tipo_match.group(1)\n",
    "            trad = trad[len(tipo_etiqueta):].lstrip('. ').strip()\n",
    "        categoria_gramatical = ''\n",
    "        cat_match = re.match(r'^(adj\\.|tr\\.|adv\\.|prep\\.|s\\.|v\\.|participio pasivo|participio activo|verbo transitivo|verbo intransitivo|adjetivo|sustantivo|pron\\.|conj\\.|interj\\.|art\\.|num\\.|part\\.|pref\\.|suf\\.)', trad)\n",
    "        if cat_match:\n",
    "            categoria_gramatical = cat_match.group(1)\n",
    "            trad = trad[len(categoria_gramatical):].lstrip('. ').strip()\n",
    "        filas.append({\n",
    "            'palabra_espanol': palabra,\n",
    "            'tipo_etiqueta': tipo_etiqueta,\n",
    "            'categoria_gramatical': categoria_gramatical,\n",
    "            'traduccion_limpia': trad\n",
    "        })\n",
    "    return filas\n",
    "\n",
    "# Usar el DataFrame df_entries_espanol_guarani ya en memoria\n",
    "filas_expandidas_eg = []\n",
    "for _, row in df_entries_espanol_guarani.iterrows():\n",
    "    filas_expandidas_eg.extend(split_multiple_translations_eg(row))\n",
    "\n",
    "df_estructurado_eg = pd.DataFrame(filas_expandidas_eg)\n",
    "\n",
    "print('Ejemplo de diccionario estructurado español-guaraní (una traducción por línea):')\n",
    "display(df_estructurado_eg.sample(10))\n",
    "df_estructurado_eg.to_csv('archivos/diccionario_espanol_guarani_estructurado.tsv', sep='\\t', index=False, encoding='utf-8')\n",
    "print('Archivo estructurado guardado: archivos/diccionario_espanol_guarani_estructurado.tsv')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
