{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mmaguero/diploma_fpuna_nlp_ia/blob/master/2025/final_project_guide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBszMmZg6LlU"
   },
   "source": [
    "# Preparación y unificación del Diccionario Guaraní-Español y Español-Guaraní para Fine-tuning\n",
    "\n",
    "En esta sección se procesan los diccionarios estructurados de ambos sentidos (español-guaraní y guaraní-español) y se unifican en un solo archivo para su uso en tareas de PLN y entrenamiento de modelos. No se generan archivos intermedios, solo el archivo final unificado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEiZQ-s-HFix"
   },
   "source": [
    "Repositorio de este proyecto:\n",
    "https://github.com/walterortiz07/proyecto_diplomado_pln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalamos las librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (0.11.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from pdfplumber) (5.2.0)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from pdfplumber) (12.0.0)\n",
      "Requirement already satisfied: pdfminer.six==20251107 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from pdfplumber) (20251107)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from pdfminer.six==20251107->pdfplumber) (3.4.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from pdfminer.six==20251107->pdfplumber) (46.0.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.13.2 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (4.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber pandas numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwKUas8OMgbY"
   },
   "source": [
    "Importamos las librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1I0OvDV0TTBU"
   },
   "outputs": [],
   "source": [
    "## Para datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pdfplumber\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ssfm-PuV65F"
   },
   "source": [
    "Abrimos el data-set como un dataframe: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
    "\n",
    "Entrada: Identificador del archivo.\n",
    "\n",
    "Salida: Una tabla DataFrame de Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fontnames únicos y su frecuencia:\n",
      "UNPVBK+ArialMT: 8096\n",
      "QMVCXS+Arial-BoldMT: 3921\n",
      "CJUWJU+Arial-BoldMT: 639\n",
      "VEGBPI+ArialMT: 344\n",
      "ZUIJTA+Alegreya-Regular: 73\n",
      "TEBKNM+SuezOne-Regular: 3\n",
      "UDQQBK+SuezOne-Regular: 2\n"
     ]
    }
   ],
   "source": [
    "# Inspeccionar fontnames únicos en las páginas relevantes para detectar negrita\n",
    "pdf_path = 'Diccionario Guaraní-Español Español-Guaraní.pdf'\n",
    "from collections import Counter\n",
    "\n",
    "def print_unique_fontnames(pdf_path, start_page, end_page):\n",
    "    fontnames = Counter()\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i in range(start_page-1, end_page):\n",
    "            page = pdf.pages[i]\n",
    "            words = page.extract_words(use_text_flow=True, keep_blank_chars=True, extra_attrs=[\"fontname\"])\n",
    "            for w in words:\n",
    "                fontnames[w.get('fontname', 'None')] += 1\n",
    "    print('Fontnames únicos y su frecuencia:')\n",
    "    for font, count in fontnames.most_common():\n",
    "        print(f'{font}: {count}')\n",
    "\n",
    "# Cambia el rango según el diccionario que quieras analizar\n",
    "print_unique_fontnames(pdf_path, 13, 85)  # Prueba con las primeras páginas del diccionario Guaraní-Español"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción paso a paso del diccionario a CSV\n",
    "A continuación, se muestra el proceso detallado y dividido en celdas para extraer las entradas del diccionario desde el PDF, construir el DataFrame y guardar los archivos CSV. El resultado final será idéntico al método anterior, pero cada paso será explicado y ejecutado por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras extraídas Guaraní-Español: 13000\n",
      "Palabras extraídas Español-Guaraní: 20548\n"
     ]
    }
   ],
   "source": [
    "# 1. Extraer palabras y atributos de las páginas relevantes del PDF\n",
    "\n",
    "def extract_words_with_attrs(pdf_path, start_page, end_page):\n",
    "    all_words = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i in range(start_page-1, end_page):\n",
    "            page = pdf.pages[i]\n",
    "            width = page.width\n",
    "            height = page.height\n",
    "            mid = width / 2\n",
    "            for col_idx, bbox in enumerate([(0, 0, mid, height), (mid, 0, width, height)]):\n",
    "                col = page.within_bbox(bbox)\n",
    "                if not col:\n",
    "                    continue\n",
    "                words = col.extract_words(use_text_flow=True, keep_blank_chars=True, extra_attrs=[\"fontname\", \"top\"])\n",
    "                words = [dict(w, page=i+1, col=col_idx+1) for w in words if not re.fullmatch(r'\\d+', w[\"text\"])]\n",
    "                all_words.extend(words)\n",
    "    return all_words\n",
    "\n",
    "# Ejemplo: extraer palabras del diccionario Guaraní-Español (páginas 13 a 85)\n",
    "words_guarani_espanol = extract_words_with_attrs(pdf_path, 13, 85)\n",
    "# Y del diccionario Español-Guaraní (páginas 87 a 213)\n",
    "words_espanol_guarani = extract_words_with_attrs(pdf_path, 87, 213)\n",
    "\n",
    "print(f\"Palabras extraídas Guaraní-Español: {len(words_guarani_espanol)}\")\n",
    "print(f\"Palabras extraídas Español-Guaraní: {len(words_espanol_guarani)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 2: Detectar inicios de línea y marcar palabras iniciales y negrita\n",
    "\n",
    "Ahora, para cada columna, detectamos los saltos de línea (por cambios en la coordenada 'top') y marcamos qué palabras son iniciales y cuáles están en negrita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>top</th>\n",
       "      <th>doctop</th>\n",
       "      <th>bottom</th>\n",
       "      <th>upright</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>direction</th>\n",
       "      <th>fontname</th>\n",
       "      <th>page</th>\n",
       "      <th>col</th>\n",
       "      <th>is_bold</th>\n",
       "      <th>is_initial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a.</td>\n",
       "      <td>56.6929</td>\n",
       "      <td>65.9769</td>\n",
       "      <td>181.6169</td>\n",
       "      <td>10284.2969</td>\n",
       "      <td>192.6169</td>\n",
       "      <td>True</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.2840</td>\n",
       "      <td>ltr</td>\n",
       "      <td>QMVCXS+Arial-BoldMT</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vocal que se pronuncia igual que en español.</td>\n",
       "      <td>65.9756</td>\n",
       "      <td>293.6382</td>\n",
       "      <td>181.0559</td>\n",
       "      <td>10283.7359</td>\n",
       "      <td>192.0559</td>\n",
       "      <td>True</td>\n",
       "      <td>11.0</td>\n",
       "      <td>227.6626</td>\n",
       "      <td>ltr</td>\n",
       "      <td>UNPVBK+ArialMT</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2. Pref. a. v. de 1ª. Per. sin. para verbos pr...</td>\n",
       "      <td>56.6929</td>\n",
       "      <td>290.5298</td>\n",
       "      <td>194.2560</td>\n",
       "      <td>10296.9360</td>\n",
       "      <td>205.2560</td>\n",
       "      <td>True</td>\n",
       "      <td>11.0</td>\n",
       "      <td>233.8369</td>\n",
       "      <td>ltr</td>\n",
       "      <td>UNPVBK+ArialMT</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ã.</td>\n",
       "      <td>56.6929</td>\n",
       "      <td>65.9775</td>\n",
       "      <td>213.6862</td>\n",
       "      <td>10316.3662</td>\n",
       "      <td>224.6862</td>\n",
       "      <td>True</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.2846</td>\n",
       "      <td>ltr</td>\n",
       "      <td>QMVCXS+Arial-BoldMT</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vocal que se pronuncia igual que la</td>\n",
       "      <td>65.9756</td>\n",
       "      <td>257.2546</td>\n",
       "      <td>213.1252</td>\n",
       "      <td>10315.8052</td>\n",
       "      <td>224.1252</td>\n",
       "      <td>True</td>\n",
       "      <td>11.0</td>\n",
       "      <td>191.2790</td>\n",
       "      <td>ltr</td>\n",
       "      <td>UNPVBK+ArialMT</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       x0        x1  \\\n",
       "0                                                 a.  56.6929   65.9769   \n",
       "1      Vocal que se pronuncia igual que en español.   65.9756  293.6382   \n",
       "2  2. Pref. a. v. de 1ª. Per. sin. para verbos pr...  56.6929  290.5298   \n",
       "3                                                 ã.  56.6929   65.9775   \n",
       "4               Vocal que se pronuncia igual que la   65.9756  257.2546   \n",
       "\n",
       "        top      doctop    bottom  upright  height     width direction  \\\n",
       "0  181.6169  10284.2969  192.6169     True    11.0    9.2840       ltr   \n",
       "1  181.0559  10283.7359  192.0559     True    11.0  227.6626       ltr   \n",
       "2  194.2560  10296.9360  205.2560     True    11.0  233.8369       ltr   \n",
       "3  213.6862  10316.3662  224.6862     True    11.0    9.2846       ltr   \n",
       "4  213.1252  10315.8052  224.1252     True    11.0  191.2790       ltr   \n",
       "\n",
       "              fontname  page  col  is_bold  is_initial  \n",
       "0  QMVCXS+Arial-BoldMT    13    1     True        True  \n",
       "1       UNPVBK+ArialMT    13    1    False       False  \n",
       "2       UNPVBK+ArialMT    13    1    False        True  \n",
       "3  QMVCXS+Arial-BoldMT    13    1     True        True  \n",
       "4       UNPVBK+ArialMT    13    1    False       False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Marcar palabras iniciales y negrita en cada columna\n",
    "\n",
    "def mark_initial_and_bold(words):\n",
    "    df = pd.DataFrame(words)\n",
    "    df['is_bold'] = df['fontname'].apply(lambda f: f is not None and f.endswith('Arial-BoldMT'))\n",
    "    df['is_initial'] = False\n",
    "    for (page, col), group in df.groupby(['page', 'col']):\n",
    "        tops = group['top'].values\n",
    "        idxs = group.index.values\n",
    "        line_starts = [0]\n",
    "        threshold = 3\n",
    "        for j in range(1, len(tops)):\n",
    "            if abs(tops[j] - tops[j-1]) > threshold:\n",
    "                line_starts.append(j)\n",
    "        df.loc[idxs[line_starts], 'is_initial'] = True\n",
    "    return df\n",
    "\n",
    "df_guarani_espanol = mark_initial_and_bold(words_guarani_espanol)\n",
    "df_espanol_guarani = mark_initial_and_bold(words_espanol_guarani)\n",
    "\n",
    "df_guarani_espanol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 3: Reconstruir las entradas (headword y traducción) a partir de las palabras marcadas\n",
    "\n",
    "Ahora, reconstruimos cada entrada del diccionario: solo cuando una palabra es inicial y negrita, se inicia una nueva entrada; el resto se concatena según las reglas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palabra</th>\n",
       "      <th>traduccion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>Vocal que se pronuncia igual que en español.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ã</td>\n",
       "      <td>Vocal que se pronuncia igual que la  a  pero  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‘a</td>\n",
       "      <td>s. Fruto, fruta.  2. Caída.  3. Huevo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‘ã</td>\n",
       "      <td>s. Ausencia.  2. Abrigo.  3. Sombra.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ache</td>\n",
       "      <td>s.  Parcialidad indígena guaraní, guayaki.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  palabra                                         traduccion\n",
       "0       a  Vocal que se pronuncia igual que en español.  ...\n",
       "1       ã  Vocal que se pronuncia igual que la  a  pero  ...\n",
       "2      ‘a             s. Fruto, fruta.  2. Caída.  3. Huevo.\n",
       "3      ‘ã               s. Ausencia.  2. Abrigo.  3. Sombra.\n",
       "4    ache         s.  Parcialidad indígena guaraní, guayaki."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Reconstruir entradas: headword (palabra en negrita inicial) y traducción\n",
    "\n",
    "def build_entries(df):\n",
    "    entries = []\n",
    "    line = ''\n",
    "    bold_headword = None\n",
    "    for _, row in df.iterrows():\n",
    "        word = row['text']\n",
    "        is_initial = row['is_initial']\n",
    "        is_bold = row['is_bold']\n",
    "        if is_initial:\n",
    "            if is_bold:\n",
    "                if line.strip() and bold_headword:\n",
    "                    palabra = bold_headword.strip().rstrip('.')\n",
    "                    traduccion = line.strip()[len(bold_headword):].lstrip(' .:;-')\n",
    "                    entries.append({'palabra': palabra, 'traduccion': traduccion})\n",
    "                line = word\n",
    "                bold_headword = word\n",
    "            else:\n",
    "                if line.strip():\n",
    "                    line += ' ' + word\n",
    "                else:\n",
    "                    line = word\n",
    "        else:\n",
    "            line += ' ' + word\n",
    "    if line.strip() and bold_headword:\n",
    "        palabra = bold_headword.strip().rstrip('.')\n",
    "        traduccion = line.strip()[len(bold_headword):].lstrip(' .:;-')\n",
    "        entries.append({'palabra': palabra, 'traduccion': traduccion})\n",
    "    return pd.DataFrame(entries)\n",
    "\n",
    "# Aplicar a ambos diccionarios\n",
    "df_entries_guarani_espanol = build_entries(df_guarani_espanol)\n",
    "df_entries_espanol_guarani = build_entries(df_espanol_guarani)\n",
    "\n",
    "df_entries_guarani_espanol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 4: Creamos la carpeta archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpeta \"archivos\" lista para guardar el archivo final unificado.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Asegurar la existencia de la carpeta donde se guardará el archivo final unificado\n",
    "os.makedirs('archivos', exist_ok=True)\n",
    "print('Carpeta \"archivos\" lista para guardar el archivo final unificado.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo estructurado guardado: archivos/diccionario_guarani_espanol_estructurado.tsv\n",
      "Archivo estructurado guardado: archivos/diccionario_espanol_guarani_estructurado.tsv\n",
      "Ejemplo guaraní-español:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palabra_guarani</th>\n",
       "      <th>tipo_etiqueta</th>\n",
       "      <th>categoria_gramatical</th>\n",
       "      <th>traduccion_limpia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>kopi</td>\n",
       "      <td></td>\n",
       "      <td>m ta</td>\n",
       "      <td>desmontar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>apykatymói</td>\n",
       "      <td></td>\n",
       "      <td>s.</td>\n",
       "      <td>Sillón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>jokapyre</td>\n",
       "      <td></td>\n",
       "      <td>adj. ra</td>\n",
       "      <td>Quebrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8420</th>\n",
       "      <td>poyhu</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sospecha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10526</th>\n",
       "      <td>teka</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4024</th>\n",
       "      <td>ka’aguygua</td>\n",
       "      <td></td>\n",
       "      <td>sa va</td>\n",
       "      <td>lvaje</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>ymaguare</td>\n",
       "      <td></td>\n",
       "      <td>s. da</td>\n",
       "      <td>Antigüedad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7527</th>\n",
       "      <td>oñoñe’ẽ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>acuerdo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3429</th>\n",
       "      <td>jerereko</td>\n",
       "      <td></td>\n",
       "      <td>s. ta</td>\n",
       "      <td>Potestad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>gua</td>\n",
       "      <td></td>\n",
       "      <td>ra</td>\n",
       "      <td>natural de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      palabra_guarani tipo_etiqueta categoria_gramatical traduccion_limpia\n",
       "4561             kopi                               m ta         desmontar\n",
       "519        apykatymói                                 s.            Sillón\n",
       "3733         jokapyre                            adj. ra          Quebrado\n",
       "8420            poyhu                                             sospecha\n",
       "10526            teka                                                    t\n",
       "4024       ka’aguygua                              sa va             lvaje\n",
       "11987        ymaguare                              s. da        Antigüedad\n",
       "7527          oñoñe’ẽ                                              acuerdo\n",
       "3429         jerereko                              s. ta          Potestad\n",
       "1042              gua                                 ra        natural de"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo español-guaraní:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palabra_espanol</th>\n",
       "      <th>tipo_etiqueta</th>\n",
       "      <th>categoria_gramatical</th>\n",
       "      <th>traduccion_limpia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11579</th>\n",
       "      <td>probar</td>\n",
       "      <td></td>\n",
       "      <td>tr.</td>\n",
       "      <td>Ha’ã</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11219</th>\n",
       "      <td>positivamente</td>\n",
       "      <td></td>\n",
       "      <td>adv.</td>\n",
       "      <td>Añetehápe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>ceniza</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>kusugue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12624</th>\n",
       "      <td>reencontrar</td>\n",
       "      <td></td>\n",
       "      <td>va</td>\n",
       "      <td>ñuvaitĩ jey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15496</th>\n",
       "      <td>vergonzoso, sa</td>\n",
       "      <td></td>\n",
       "      <td>m va.</td>\n",
       "      <td>oporomotĩva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15242</th>\n",
       "      <td>vacilante</td>\n",
       "      <td></td>\n",
       "      <td>adj. va</td>\n",
       "      <td>Vava</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14337</th>\n",
       "      <td>sobriedad</td>\n",
       "      <td></td>\n",
       "      <td>f.</td>\n",
       "      <td>Ka’u’ỹ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13580</th>\n",
       "      <td>rugido</td>\n",
       "      <td></td>\n",
       "      <td>m</td>\n",
       "      <td>py’ambu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12567</th>\n",
       "      <td>red</td>\n",
       "      <td></td>\n",
       "      <td>ra</td>\n",
       "      <td>pira ñuhã</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12589</th>\n",
       "      <td>redondear</td>\n",
       "      <td></td>\n",
       "      <td>tr.</td>\n",
       "      <td>Mboapu’a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      palabra_espanol tipo_etiqueta categoria_gramatical traduccion_limpia\n",
       "11579          probar                                tr.              Ha’ã\n",
       "11219   positivamente                               adv.         Añetehápe\n",
       "2114           ceniza                                              kusugue\n",
       "12624     reencontrar                                 va       ñuvaitĩ jey\n",
       "15496  vergonzoso, sa                              m va.       oporomotĩva\n",
       "15242       vacilante                            adj. va              Vava\n",
       "14337       sobriedad                                 f.            Ka’u’ỹ\n",
       "13580          rugido                                  m           py’ambu\n",
       "12567             red                                 ra         pira ñuhã\n",
       "12589       redondear                                tr.          Mboapu’a"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Extracción robusta de todas las abreviaturas para ambos diccionarios (actualizado con nuevas abreviaturas y limpieza de numeraciones residuales) ---\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Listas de abreviaturas\n",
    "TIPOS_ETIQUETA = ['neol.', 'arc.', 'h.']\n",
    "CATEGORIAS_GRAMATICALES = [\n",
    "    'adj.', 'tr.', 'adv.', 'prep.', 's.', 'v.', 'participio pasivo', 'participio activo',\n",
    "    'verbo transitivo', 'verbo intransitivo', 'adjetivo', 'sustantivo', 'pron.', 'conj.', 'interj.',\n",
    "    'art.', 'num.', 'part.', 'pref.', 'suf.', 'f.', 'm.', 'ta.', 'Tr.', 'prnl.', 'ra.', 'com.', 'int.', 'va.',\n",
    "    'da.', 'intr.', 'sa.', 'y f.', 'm y f.', 'va.', 'intrans.', 'trans.', 'exp.', 'pl.', 'dem.', 'sing.', 'rel.', 'int.', 'com.', 'adj', 'intr', 'tr', 'f', 'm', 'ta', 'da', 'sa', 'va', 'ra', 'com', 'int', 'pl', 'dem', 'sing', 'rel', 'exp', 'prnl', 'intrans', 'trans', 'gram.',\n",
    "    # Nuevas abreviaturas encontradas:\n",
    "    'atr.', 'adv .', 'ind.', 'neg.', 'pr.'\n",
    "]\n",
    "# Unir ambas listas para búsqueda general\n",
    "ALL_ABBR = TIPOS_ETIQUETA + CATEGORIAS_GRAMATICALES\n",
    "# Ordenar por longitud descendente para evitar capturas parciales\n",
    "ALL_ABBR = sorted(set(ALL_ABBR), key=len, reverse=True)\n",
    "ABBR_REGEX = r'|'.join([re.escape(a) for a in ALL_ABBR])\n",
    "\n",
    "# Función robusta de extracción de todas las abreviaturas\n",
    "def extract_labels_and_clean(text):\n",
    "    # Buscar todas las abreviaturas en cualquier parte del texto\n",
    "    abbrs = re.findall(rf'({ABBR_REGEX})', text)\n",
    "    tipo_etiqueta = []\n",
    "    categoria_gramatical = []\n",
    "    for abbr in abbrs:\n",
    "        if abbr in TIPOS_ETIQUETA:\n",
    "            tipo_etiqueta.append(abbr)\n",
    "        elif abbr in CATEGORIAS_GRAMATICALES:\n",
    "            categoria_gramatical.append(abbr)\n",
    "    # Eliminar todas las abreviaturas encontradas del texto\n",
    "    for abbr in abbrs:\n",
    "        text = re.sub(rf'\\b{re.escape(abbr)}[\\s,.]*', '', text)\n",
    "    text = text.lstrip('. ').strip()\n",
    "    # Quitar punto final si existe\n",
    "    text = text.rstrip('.')\n",
    "    # Eliminar numeraciones residuales (ej: '2.', '3.', etc. al inicio o en medio)\n",
    "    text = re.sub(r'(\\b\\d+\\.)', '', text).strip()\n",
    "    # Eliminar espacios dobles generados\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return ' '.join(tipo_etiqueta), ' '.join(categoria_gramatical), text\n",
    "\n",
    "def split_and_expand(row, sentido):\n",
    "    if sentido == 'ge':\n",
    "        palabra_col = 'palabra' if 'palabra' in row else 'palabra_guarani'\n",
    "        palabra = row.get(palabra_col, '')\n",
    "    else:\n",
    "        palabra_col = 'palabra' if 'palabra' in row else 'palabra_espanol'\n",
    "        palabra = row.get(palabra_col, '')\n",
    "    output = str(row['traduccion']) if 'traduccion' in row else str(row.get('output', ''))\n",
    "    output = output if not pd.isnull(output) else ''\n",
    "    # Separar por número (2., 3., ...)\n",
    "    partes = re.split(r'(?<=\\.)\\s*(\\d+\\.)\\s*', output)\n",
    "    traducciones = []\n",
    "    if partes:\n",
    "        traducciones.append(partes[0].strip())\n",
    "        for i in range(1, len(partes), 2):\n",
    "            traducciones.append(partes[i+1].strip() if i+1 < len(partes) else '')\n",
    "    else:\n",
    "        traducciones = [output.strip()]\n",
    "    filas = []\n",
    "    for trad in traducciones:\n",
    "        subtrads = [t.strip() for t in trad.split(',') if t.strip()]\n",
    "        for subtrad in subtrads:\n",
    "            tipo_etiqueta, categoria_gramatical, subtrad_limpia = extract_labels_and_clean(subtrad)\n",
    "            if sentido == 'ge':\n",
    "                fila = {\n",
    "                    'palabra_guarani': palabra,\n",
    "                    'tipo_etiqueta': tipo_etiqueta,\n",
    "                    'categoria_gramatical': categoria_gramatical,\n",
    "                    'traduccion_limpia': subtrad_limpia\n",
    "                }\n",
    "            else:\n",
    "                fila = {\n",
    "                    'palabra_espanol': palabra,\n",
    "                    'tipo_etiqueta': tipo_etiqueta,\n",
    "                    'categoria_gramatical': categoria_gramatical,\n",
    "                    'traduccion_limpia': subtrad_limpia\n",
    "                }\n",
    "            filas.append(fila)\n",
    "    return filas\n",
    "\n",
    "# Procesar guaraní-español\n",
    "ge_expandidas = []\n",
    "for _, row in df_entries_guarani_espanol.iterrows():\n",
    "    ge_expandidas.extend(split_and_expand(row, 'ge'))\n",
    "df_estructurado_ge = pd.DataFrame(ge_expandidas)\n",
    "cols_ge = ['palabra_guarani', 'tipo_etiqueta', 'categoria_gramatical', 'traduccion_limpia']\n",
    "df_estructurado_ge = df_estructurado_ge[cols_ge]\n",
    "# Eliminar filas vacías en traduccion_limpia\n",
    "df_estructurado_ge = df_estructurado_ge[df_estructurado_ge['traduccion_limpia'].str.strip() != '']\n",
    "df_estructurado_ge.to_csv('archivos/diccionario_guarani_espanol_estructurado.tsv', sep='\\t', index=False, encoding='utf-8')\n",
    "print('Archivo estructurado guardado: archivos/diccionario_guarani_espanol_estructurado.tsv')\n",
    "\n",
    "# Procesar español-guaraní\n",
    "eg_expandidas = []\n",
    "for _, row in df_entries_espanol_guarani.iterrows():\n",
    "    eg_expandidas.extend(split_and_expand(row, 'eg'))\n",
    "df_estructurado_eg = pd.DataFrame(eg_expandidas)\n",
    "cols_eg = ['palabra_espanol', 'tipo_etiqueta', 'categoria_gramatical', 'traduccion_limpia']\n",
    "df_estructurado_eg = df_estructurado_eg[cols_eg]\n",
    "# Eliminar filas vacías en traduccion_limpia\n",
    "df_estructurado_eg = df_estructurado_eg[df_estructurado_eg['traduccion_limpia'].str.strip() != '']\n",
    "df_estructurado_eg.to_csv('archivos/diccionario_espanol_guarani_estructurado.tsv', sep='\\t', index=False, encoding='utf-8')\n",
    "print('Archivo estructurado guardado: archivos/diccionario_espanol_guarani_estructurado.tsv')\n",
    "\n",
    "from IPython.display import display\n",
    "print('Ejemplo guaraní-español:')\n",
    "display(df_estructurado_ge.sample(10))\n",
    "print('Ejemplo español-guaraní:')\n",
    "display(df_estructurado_eg.sample(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo de diccionario estructurado español-guaraní (una traducción por línea):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palabra_espanol</th>\n",
       "      <th>tipo_etiqueta</th>\n",
       "      <th>categoria_gramatical</th>\n",
       "      <th>traduccion_limpia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>lustre</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>m. Mimbi, vera.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>disputa</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>f. Ñorairõ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5368</th>\n",
       "      <td>microcosmos</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>m. Arapy michĩ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9120</th>\n",
       "      <td>velar</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>intr.  Iko  páype,  hesa  ke’ỹme.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6727</th>\n",
       "      <td>pluviómetro</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>m. Ama ra’ãha.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7731</th>\n",
       "      <td>rencor</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>m. Py’aro, py’araku.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>disolvente</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>m. Mbohykuha.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7908</th>\n",
       "      <td>retobarse</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>prnl. Ñembopochy, mbohovái.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>yelmo</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>m. Akãngaoratã.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7913</th>\n",
       "      <td>retorcijón</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>m. Tyerasy kutu.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     palabra_espanol tipo_etiqueta categoria_gramatical  \\\n",
       "4982          lustre                                      \n",
       "2440         disputa                                      \n",
       "5368     microcosmos                                      \n",
       "9120           velar                                      \n",
       "6727     pluviómetro                                      \n",
       "7731          rencor                                      \n",
       "2431      disolvente                                      \n",
       "7908       retobarse                                      \n",
       "9356           yelmo                                      \n",
       "7913      retorcijón                                      \n",
       "\n",
       "                      traduccion_limpia  \n",
       "4982                    m. Mimbi, vera.  \n",
       "2440                        f. Ñorairõ.  \n",
       "5368                    m. Arapy michĩ.  \n",
       "9120  intr.  Iko  páype,  hesa  ke’ỹme.  \n",
       "6727                     m. Ama ra’ãha.  \n",
       "7731               m. Py’aro, py’araku.  \n",
       "2431                      m. Mbohykuha.  \n",
       "7908        prnl. Ñembopochy, mbohovái.  \n",
       "9356                    m. Akãngaoratã.  \n",
       "7913                   m. Tyerasy kutu.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo estructurado guardado: archivos/diccionario_espanol_guarani_estructurado.tsv\n"
     ]
    }
   ],
   "source": [
    "# --- Normalización granular y desdoblamiento de traducciones múltiples (español-guaraní) ---\n",
    "def split_multiple_translations_eg(row):\n",
    "    \"\"\"\n",
    "    Divide las traducciones separadas por números (2. 3. 4. ...) en líneas independientes,\n",
    "    manteniendo la palabra_espanol y extrayendo tipo_etiqueta y categoria_gramatical para cada una.\n",
    "    \"\"\"\n",
    "    palabra = row['palabra'] if 'palabra' in row else row['palabra_espanol']\n",
    "    output = str(row['traduccion']) if 'traduccion' in row else str(row['output'])\n",
    "    output = output if not pd.isnull(output) else ''\n",
    "    partes = re.split(r'(?<=\\.)\\s*(\\d+\\.)\\s*', output)\n",
    "    traducciones = []\n",
    "    if partes:\n",
    "        traducciones.append(partes[0].strip())\n",
    "        for i in range(1, len(partes), 2):\n",
    "            traducciones.append(partes[i+1].strip() if i+1 < len(partes) else '')\n",
    "    else:\n",
    "        traducciones = [output.strip()]\n",
    "    filas = []\n",
    "    for trad in traducciones:\n",
    "        tipo_etiqueta = ''\n",
    "        tipo_match = re.match(r'^(neol\\.|arc\\.|h\\.)', trad)\n",
    "        if tipo_match:\n",
    "            tipo_etiqueta = tipo_match.group(1)\n",
    "            trad = trad[len(tipo_etiqueta):].lstrip('. ').strip()\n",
    "        categoria_gramatical = ''\n",
    "        cat_match = re.match(r'^(adj\\.|tr\\.|adv\\.|prep\\.|s\\.|v\\.|participio pasivo|participio activo|verbo transitivo|verbo intransitivo|adjetivo|sustantivo|pron\\.|conj\\.|interj\\.|art\\.|num\\.|part\\.|pref\\.|suf\\.)', trad)\n",
    "        if cat_match:\n",
    "            categoria_gramatical = cat_match.group(1)\n",
    "            trad = trad[len(categoria_gramatical):].lstrip('. ').strip()\n",
    "        filas.append({\n",
    "            'palabra_espanol': palabra,\n",
    "            'tipo_etiqueta': tipo_etiqueta,\n",
    "            'categoria_gramatical': categoria_gramatical,\n",
    "            'traduccion_limpia': trad\n",
    "        })\n",
    "    return filas\n",
    "\n",
    "# Usar el DataFrame df_entries_espanol_guarani ya en memoria\n",
    "filas_expandidas_eg = []\n",
    "for _, row in df_entries_espanol_guarani.iterrows():\n",
    "    filas_expandidas_eg.extend(split_multiple_translations_eg(row))\n",
    "\n",
    "df_estructurado_eg = pd.DataFrame(filas_expandidas_eg)\n",
    "\n",
    "print('Ejemplo de diccionario estructurado español-guaraní (una traducción por línea):')\n",
    "display(df_estructurado_eg.sample(10))\n",
    "df_estructurado_eg.to_csv('archivos/diccionario_espanol_guarani_estructurado.tsv', sep='\\t', index=False, encoding='utf-8')\n",
    "print('Archivo estructurado guardado: archivos/diccionario_espanol_guarani_estructurado.tsv')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
