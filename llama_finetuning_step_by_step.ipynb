{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fc15fca",
   "metadata": {},
   "source": [
    "# Fine-tuning paso a paso: Llama-3.2-1B con AmericasNLP y diccionario estructurado\n",
    "\n",
    "Este notebook guía el proceso completo y reproducible para ajustar un modelo LLM (meta-llama/Llama-3.2-1B) usando HuggingFace Transformers, con datos de AmericasNLP y un diccionario estructurado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c45c23",
   "metadata": {},
   "source": [
    "## 1. Importar librerías necesarias\n",
    "\n",
    "Instala y carga todas las librerías requeridas para el fine-tuning reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18076a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\Scripts\\python.exe -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\Scripts\\python.exe -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\Scripts\\python.exe -m pip install [options] [-e] <vcs project url> ...\n",
      "  c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\Scripts\\python.exe -m pip install [options] [-e] <local project path> ...\n",
      "  c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\Scripts\\python.exe -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -y\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall -y transformers accelerate peft sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0429cb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping torch as it is not installed.\n",
      "WARNING: Skipping torchvision as it is not installed.\n",
      "WARNING: Skipping torchaudio as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch==2.2.2+cu121\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.2.2%2Bcu121-cp310-cp310-win_amd64.whl (2454.8 MB)\n",
      "     ---------------------------------------- 2.5/2.5 GB 580.4 kB/s eta 0:00:00\n",
      "Collecting torchvision==0.17.2+cu121\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.17.2%2Bcu121-cp310-cp310-win_amd64.whl (5.7 MB)\n",
      "     ---------------------------------------- 5.7/5.7 MB 32.8 MB/s eta 0:00:00\n",
      "Collecting torchaudio==2.2.2+cu121\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.2.2%2Bcu121-cp310-cp310-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 4.1/4.1 MB 28.8 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Collecting networkx\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 32.6 MB/s eta 0:00:00\n",
      "Collecting fsspec\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "     ------------------------------------- 199.3/199.3 kB 11.8 MB/s eta 0:00:00\n",
      "Collecting jinja2\n",
      "  Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "     -------------------------------------- 134.9/134.9 kB 7.8 MB/s eta 0:00:00\n",
      "Collecting sympy\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 6.3/6.3 MB 31.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from torch==2.2.2+cu121) (4.15.0)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading https://download.pytorch.org/whl/pillow-11.3.0-cp310-cp310-win_amd64.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 29.7 MB/s eta 0:00:00\n",
      "Collecting numpy\n",
      "  Downloading https://download.pytorch.org/whl/numpy-2.1.2-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "     --------------------------------------- 12.9/12.9 MB 29.8 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp310-cp310-win_amd64.whl (17 kB)\n",
      "Collecting networkx\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 21.7 MB/s eta 0:00:00\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ------------------------------------- 536.2/536.2 kB 17.0 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, pillow, numpy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.19.1 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.3 numpy-2.1.2 pillow-11.3.0 sympy-1.14.0 torch-2.2.2+cu121 torchaudio-2.2.2+cu121 torchvision-0.17.2+cu121\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\walte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\walte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\walte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\walte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\walte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\ipykernel\\utils.py\", line 71, in preserve_context\n",
      "    return await f(*args, **kwargs)\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\walte\\AppData\\Local\\Temp\\ipykernel_8812\\1850710114.py\", line 5, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\torch\\__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\walte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\walte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\walte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\walte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\walte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\ipykernel\\utils.py\", line 71, in preserve_context\n",
      "    return await f(*args, **kwargs)\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\walte\\AppData\\Local\\Temp\\ipykernel_8812\\1850710114.py\", line 5, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\torch\\__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.2.2+cu121\n",
      "CUDA disponible: True\n",
      "Versión CUDA (PyTorch): 12.1\n",
      "Dispositivos CUDA: 1\n",
      "Nombre GPU: NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall -y torch torchvision torchaudio\n",
    "%pip install torch==2.2.2+cu121 torchvision==0.17.2+cu121 torchaudio==2.2.2+cu121 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Verificar instalación y soporte CUDA\n",
    "import torch\n",
    "print('torch version:', torch.__version__)\n",
    "print('CUDA disponible:', torch.cuda.is_available())\n",
    "print('Versión CUDA (PyTorch):', torch.version.cuda)\n",
    "print('Dispositivos CUDA:', torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print('Nombre GPU:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a34dddf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (4.57.3)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: datasets in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: accelerate in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: requests in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: fsspec[http]<=2025.10.0,>=2023.1.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from datasets) (2025.9.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from accelerate) (2.2.2+cu121)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: idna in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: anyio in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from requests->transformers) (2.6.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install -U transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fef94696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "     --------------------------------------- 12.0/12.0 MB 27.3 MB/s eta 0:00:00\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "     ------------------------------------- 380.9/380.9 kB 23.2 MB/s eta 0:00:00\n",
      "Collecting peft\n",
      "  Downloading peft-0.18.0-py3-none-any.whl (556 kB)\n",
      "     ------------------------------------- 556.4/556.4 kB 36.4 MB/s eta 0:00:00\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n",
      "     ------------------------------------- 493.7/493.7 kB 15.6 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub<1.0,>=0.34.0\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "     ------------------------------------- 566.1/566.1 kB 34.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "     ---------------------------------------- 2.7/2.7 MB 28.3 MB/s eta 0:00:00\n",
      "Collecting safetensors>=0.4.3\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "     ------------------------------------- 341.4/341.4 kB 10.7 MB/s eta 0:00:00\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.5/78.5 kB 4.3 MB/s eta 0:00:00\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2025.11.3-cp310-cp310-win_amd64.whl (277 kB)\n",
      "     ---------------------------------------- 277.7/277.7 kB ? eta 0:00:00\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading pyyaml-6.0.3-cp310-cp310-win_amd64.whl (158 kB)\n",
      "     -------------------------------------- 158.6/158.6 kB 9.9 MB/s eta 0:00:00\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "     ---------------------------------------- 64.7/64.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from accelerate) (2.2.2+cu121)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp310-cp310-win_amd64.whl (8.9 MB)\n",
      "     ---------------------------------------- 8.9/8.9 MB 28.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "     --------------------------------------- 41.3/41.3 MB 22.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: sympy in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting charset_normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl (107 kB)\n",
      "     -------------------------------------- 107.2/107.2 kB 6.1 MB/s eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "     -------------------------------------- 159.4/159.4 kB 9.9 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "     ---------------------------------------- 71.0/71.0 kB ? eta 0:00:00\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "     -------------------------------------- 131.2/131.2 kB 7.6 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "     ------------------------------------- 309.1/309.1 kB 19.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Installing collected packages: urllib3, tqdm, threadpoolctl, scipy, safetensors, regex, pyyaml, joblib, idna, charset_normalizer, certifi, scikit-learn, requests, huggingface-hub, tokenizers, accelerate, transformers, sentence-transformers, peft\n",
      "Successfully installed accelerate-1.12.0 certifi-2025.11.12 charset_normalizer-3.4.4 huggingface-hub-0.36.0 idna-3.11 joblib-1.5.3 peft-0.18.0 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 scikit-learn-1.7.2 scipy-1.15.3 sentence-transformers-5.2.0 threadpoolctl-3.6.0 tokenizers-0.22.1 tqdm-4.67.1 transformers-4.57.3 urllib3-2.6.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers accelerate peft sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a169b588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.2.2+cu121\n",
      "Transformers: 4.57.3\n",
      "Accelerate: 1.12.0\n",
      "PEFT: 0.18.0\n",
      "Sentence-Transformers: 5.2.0\n",
      "✔ Todas las librerías principales están instaladas\n"
     ]
    }
   ],
   "source": [
    "# Verificar instalación y versiones de librerías principales\n",
    "missing = []\n",
    "try:\n",
    "    import torch\n",
    "    print(f'Torch: {torch.__version__}')\n",
    "except ImportError:\n",
    "    print('Torch: NO INSTALADO')\n",
    "    missing.append('torch')\n",
    "try:\n",
    "    import transformers\n",
    "    print(f'Transformers: {transformers.__version__}')\n",
    "except ImportError:\n",
    "    print('Transformers: NO INSTALADO')\n",
    "    missing.append('transformers')\n",
    "try:\n",
    "    import accelerate\n",
    "    print(f'Accelerate: {accelerate.__version__}')\n",
    "except ImportError:\n",
    "    print('Accelerate: NO INSTALADO')\n",
    "    missing.append('accelerate')\n",
    "try:\n",
    "    import peft\n",
    "    print(f'PEFT: {peft.__version__}')\n",
    "except ImportError:\n",
    "    print('PEFT: NO INSTALADO')\n",
    "    missing.append('peft')\n",
    "try:\n",
    "    import sentence_transformers\n",
    "    print(f'Sentence-Transformers: {sentence_transformers.__version__}')\n",
    "except ImportError:\n",
    "    print('Sentence-Transformers: NO INSTALADO')\n",
    "    missing.append('sentence-transformers')\n",
    "if missing:\n",
    "    print('❌ Faltan librerías:', ', '.join(missing))\n",
    "else:\n",
    "    print('✔ Todas las librerías principales están instaladas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8cf15fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python ejecutable: c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python ejecutable:\", sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c45f62",
   "metadata": {},
   "source": [
    "Reiniciar Kernels:\n",
    "Ctrl + Shift + P\n",
    "Jupyter: Restart Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eb7eb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers: 4.57.3\n",
      "Accelerate: 1.12.0\n",
      "PEFT: 0.18.0\n",
      "Torch: 2.2.2+cu121\n",
      "✔ Versiones correctas\n"
     ]
    }
   ],
   "source": [
    "import transformers, accelerate, peft, torch\n",
    "\n",
    "print(\"Transformers:\", transformers.__version__)\n",
    "print(\"Accelerate:\", accelerate.__version__)\n",
    "print(\"PEFT:\", peft.__version__)\n",
    "print(\"Torch:\", torch.__version__)\n",
    "\n",
    "# assert transformers.__version__ == \"4.38.2\"\n",
    "# assert accelerate.__version__ == \"0.27.2\"\n",
    "# assert peft.__version__ == \"0.9.0\"\n",
    "\n",
    "print(\"✔ Versiones correctas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "774784ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "     -------------------------------------- 511.6/511.6 kB 4.6 MB/s eta 0:00:00\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.6.0-cp310-cp310-win_amd64.whl (31 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "     --------------------------------------- 11.3/11.3 MB 26.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: fsspec[http]<=2025.10.0,>=2023.1.0 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from datasets) (2025.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from datasets) (2.1.2)\n",
      "Collecting dill<0.4.1,>=0.3.0\n",
      "  Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "     -------------------------------------- 119.7/119.7 kB 7.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Collecting httpx<1.0.0\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "     ---------------------------------------- 73.5/73.5 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from datasets) (3.19.1)\n",
      "Collecting multiprocess<0.70.19\n",
      "  Downloading multiprocess-0.70.18-py310-none-any.whl (134 kB)\n",
      "     ---------------------------------------- 134.9/134.9 kB ? eta 0:00:00\n",
      "Collecting pyarrow>=21.0.0\n",
      "  Downloading pyarrow-22.0.0-cp310-cp310-win_amd64.whl (28.1 MB)\n",
      "     --------------------------------------- 28.1/28.1 MB 21.1 MB/s eta 0:00:00\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.13.2-cp310-cp310-win_amd64.whl (455 kB)\n",
      "     ------------------------------------- 455.1/455.1 kB 27.8 MB/s eta 0:00:00\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.8/78.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: idna in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Collecting anyio\n",
      "  Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "     -------------------------------------- 113.4/113.4 kB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Collecting h11>=0.16\n",
      "  Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.6.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "     ------------------------------------- 348.5/348.5 kB 21.1 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "     ------------------------------------- 509.2/509.2 kB 31.2 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.4.0\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.4.1-cp310-cp310-win_amd64.whl (41 kB)\n",
      "     ---------------------------------------- 41.6/41.6 kB ? eta 0:00:00\n",
      "Collecting aiohappyeyeballs>=2.5.0\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.8.0-cp310-cp310-win_amd64.whl (43 kB)\n",
      "     ---------------------------------------- 43.8/43.8 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.22.0-cp310-cp310-win_amd64.whl (86 kB)\n",
      "     ---------------------------------------- 86.9/86.9 kB ? eta 0:00:00\n",
      "Collecting async-timeout<6.0,>=4.0\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.7.0-cp310-cp310-win_amd64.whl (46 kB)\n",
      "     ---------------------------------------- 46.0/46.0 kB ? eta 0:00:00\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "     ---------------------------------------- 67.6/67.6 kB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\walte\\desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Installing collected packages: pytz, xxhash, tzdata, pyarrow, propcache, multidict, h11, frozenlist, dill, attrs, async-timeout, aiohappyeyeballs, yarl, pandas, multiprocess, httpcore, anyio, aiosignal, httpx, aiohttp, datasets\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 anyio-4.12.0 async-timeout-5.0.1 attrs-25.4.0 datasets-4.4.1 dill-0.4.0 frozenlist-1.8.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 multidict-6.7.0 multiprocess-0.70.18 pandas-2.3.3 propcache-0.4.1 pyarrow-22.0.0 pytz-2025.2 tzdata-2025.3 xxhash-3.6.0 yarl-1.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "451690f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.26.4Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Uninstalling numpy-1.26.4:\n",
      "  Successfully uninstalled numpy-1.26.4\n",
      "Collecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall -y numpy\n",
    "%pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31115902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\walte\\Desktop\\pln\\proyecto_diplomado_pln\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Imports OK\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "print(\"✔ Imports OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1abee452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce GTX 1070\n",
      "✔ Semilla fijada\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"⚠️ CUDA no disponible\")\n",
    "\n",
    "print(\"✔ Semilla fijada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf0f728",
   "metadata": {},
   "source": [
    "## 2. Cargar y preparar el conjunto de datos\n",
    "\n",
    "Cargamos los archivos de AmericasNLP y el diccionario estructurado, y preparamos los pares (input, output) para el fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd52eeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (178, 4) | Dev: (79, 4) | Test: (364, 4)\n",
      "Diccionario guaraní-español: (12073, 4)\n",
      "Diccionario español-guaraní: (9425, 4)\n",
      "Ejemplo guaraní-español:\n",
      "  palabra_guarani tipo_etiqueta categoria_gramatical  \\\n",
      "0               a           NaN                  NaN   \n",
      "1               a           NaN          f. v. ra s.   \n",
      "2               ã           NaN                 m sa   \n",
      "3               ã           NaN            adj. dem.   \n",
      "4               ã           NaN                ta s.   \n",
      "\n",
      "                                   traduccion_limpia  \n",
      "0        Vocal que se pronuncia igual que en español  \n",
      "1      Pref. a. de 1ª. Per. sin. para verbos propios  \n",
      "2  Vocal que se pronuncia igual que la a pero con...  \n",
      "3                                              Estos  \n",
      "4                                              estas  \n",
      "Ejemplo español-guaraní:\n",
      "  palabra_espanol tipo_etiqueta categoria_gramatical  \\\n",
      "0               a           NaN                  NaN   \n",
      "1               a           NaN                prep.   \n",
      "2           abajo           NaN                 adv.   \n",
      "3     abanderado,           NaN                  NaN   \n",
      "4     abandonado,           NaN                  NaN   \n",
      "\n",
      "               traduccion_limpia  \n",
      "0  f. Pu’ae avañe’ẽmeicha ipúva.  \n",
      "1         Pe, me,  ve, re, rehe.  \n",
      "2                  Yvýpe, guýpe.  \n",
      "3    da.  m y f. Poyvi rerahaha.  \n",
      "4              da.  adj. jeheja.  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar AmericasNLP (train/dev/test)\n",
    "train_path = 'AmericasNLP/guarani-train.tsv'\n",
    "dev_path = 'AmericasNLP/guarani-dev.tsv'\n",
    "test_path = 'AmericasNLP/guarani-test.tsv'\n",
    "\n",
    "try:\n",
    "    df_train = pd.read_csv(train_path, sep='\\t')\n",
    "    df_dev = pd.read_csv(dev_path, sep='\\t')\n",
    "    df_test = pd.read_csv(test_path, sep='\\t')\n",
    "    print('Train:', df_train.shape, '| Dev:', df_dev.shape, '| Test:', df_test.shape)\n",
    "except Exception as e:\n",
    "    print('Error cargando AmericasNLP:', e)\n",
    "\n",
    "# Cargar diccionarios estructurados de la carpeta archivos\n",
    "dict_ge_path = 'archivos/diccionario_guarani_espanol_estructurado.tsv'\n",
    "dict_eg_path = 'archivos/diccionario_espanol_guarani_estructurado.tsv'\n",
    "\n",
    "try:\n",
    "    df_dict_ge = pd.read_csv(dict_ge_path, sep='\\t')\n",
    "    print('Diccionario guaraní-español:', df_dict_ge.shape)\n",
    "except Exception as e:\n",
    "    print('Error cargando diccionario guaraní-español:', e)\n",
    "\n",
    "try:\n",
    "    df_dict_eg = pd.read_csv(dict_eg_path, sep='\\t')\n",
    "    print('Diccionario español-guaraní:', df_dict_eg.shape)\n",
    "except Exception as e:\n",
    "    print('Error cargando diccionario español-guaraní:', e)\n",
    "\n",
    "# Ejemplo de los primeros registros de cada diccionario\n",
    "print('Ejemplo guaraní-español:')\n",
    "print(df_dict_ge.head())\n",
    "print('Ejemplo español-guaraní:')\n",
    "print(df_dict_eg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1060184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo español-guaraní estructurado:\n",
      "         input                         output\n",
      "0            a  f. Pu’ae avañe’ẽmeicha ipúva.\n",
      "1            a         Pe, me,  ve, re, rehe.\n",
      "2        abajo                  Yvýpe, guýpe.\n",
      "3  abanderado,    da.  m y f. Poyvi rerahaha.\n",
      "4  abandonado,              da.  adj. jeheja.\n",
      "Ejemplo guaraní-español estructurado:\n",
      "  input                                             output\n",
      "0     a        Vocal que se pronuncia igual que en español\n",
      "1     a      Pref. a. de 1ª. Per. sin. para verbos propios\n",
      "2     ã  Vocal que se pronuncia igual que la a pero con...\n",
      "3     ã                                              Estos\n",
      "4     ã                                              estas\n"
     ]
    }
   ],
   "source": [
    "# Preprocesar los diccionarios estructurados para tareas de traducción\n",
    "if 'df_dict_eg' in locals():\n",
    "    dict_data_eg = df_dict_eg[['palabra_espanol', 'traduccion_limpia']].copy()\n",
    "    dict_data_eg = dict_data_eg.rename(columns={'palabra_espanol': 'input', 'traduccion_limpia': 'output'})\n",
    "    print('Ejemplo español-guaraní estructurado:')\n",
    "    print(dict_data_eg.head())\n",
    "else:\n",
    "    print('No se cargó el diccionario español-guaraní.')\n",
    "\n",
    "if 'df_dict_ge' in locals():\n",
    "    dict_data_ge = df_dict_ge[['palabra_guarani', 'traduccion_limpia']].copy()\n",
    "    dict_data_ge = dict_data_ge.rename(columns={'palabra_guarani': 'input', 'traduccion_limpia': 'output'})\n",
    "    print('Ejemplo guaraní-español estructurado:')\n",
    "    print(dict_data_ge.head())\n",
    "else:\n",
    "    print('No se cargó el diccionario guaraní-español.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "756bb2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               input  \\\n",
      "0  Ha’e ombojerekuri umi kutuhakuéra poro’o [PERS...   \n",
      "1  Ha’e ombojerekuri umi kutuhakuéra poro’o [TYPE...   \n",
      "2  Ha’e ombojerekuri umi kutuhakuéra poro’o [ASPE...   \n",
      "3    Mombe’ukuéra omboty kuri pende arete [TYPE:NEG]   \n",
      "4  Mombe’ukuéra omboty kuri pende arete [ASPECT:I...   \n",
      "\n",
      "                                            output  \n",
      "0       Nde rembojerekuri umi kutuhakuéra tuicháva  \n",
      "1    Ha’e ndombojereikuri umi kutuhakuéra tuicháva  \n",
      "2  Ha’e ombojerehina kuri umi kutuhakuéra tuicháva  \n",
      "3          Mombe’ukuéra ndombotyi kuri pende arete  \n",
      "4        Mombe’ukuéra omboty kuri hína pende arete  \n"
     ]
    }
   ],
   "source": [
    "# Preprocesar AmericasNLP: crear pares (input, output) para fine-tuning\n",
    "\n",
    "def build_input(row):\n",
    "    return f\"{row['Source']} [{row['Change']}]\"\n",
    "\n",
    "df_train = df_train.dropna(subset=['Source', 'Change', 'Target'])\n",
    "df_dev = df_dev.dropna(subset=['Source', 'Change', 'Target'])\n",
    "\n",
    "train_data = pd.DataFrame({\n",
    "    'input': df_train.apply(build_input, axis=1),\n",
    "    'output': df_train['Target']\n",
    "})\n",
    "dev_data = pd.DataFrame({\n",
    "    'input': df_dev.apply(build_input, axis=1),\n",
    "    'output': df_dev['Target']\n",
    "})\n",
    "\n",
    "# Concatenar los datos de los diccionarios estructurados para aumentar el set de entrenamiento\n",
    "train_data = pd.concat([train_data, dict_data_eg, dict_data_ge], ignore_index=True)\n",
    "\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7388c3",
   "metadata": {},
   "source": [
    "## 3. Tokenización de los datos\n",
    "\n",
    "Utilizamos el tokenizer del modelo base para convertir los textos en tensores adecuados para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6729a437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 21676/21676 [00:01<00:00, 13510.67 examples/s]\n",
      "Map: 100%|██████████| 79/79 [00:00<00:00, 7180.78 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input', 'output', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 21676\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input', 'output', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 79\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar el tokenizer de Bloom-560m desde HuggingFace\n",
    "model_name = 'bigscience/bloom-560m'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenización de los datos de entrenamiento y validación\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example['input'], truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "# Convertir a HuggingFace Dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "train_hf = Dataset.from_pandas(train_data)\n",
    "dev_hf = Dataset.from_pandas(dev_data)\n",
    "\n",
    "datasets = DatasetDict({\n",
    "    'train': train_hf,\n",
    "    'validation': dev_hf\n",
    "})\n",
    "\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True)\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054462f",
   "metadata": {},
   "source": [
    "## 4. Configurar el modelo base para fine tuning\n",
    "\n",
    "Cargamos el modelo preentrenado Llama-3.2-1B y lo preparamos para el ajuste fino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b781d01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado: bigscience/bloom-560m\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo base para causal language modeling (Bloom-560m)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "print('Modelo cargado:', model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665c83be",
   "metadata": {},
   "source": [
    "## 5. Definir hiperparámetros y configuración de entrenamiento\n",
    "\n",
    "Establecemos los parámetros principales para el entrenamiento reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75e41dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./finetuned',\n",
    "#     evaluation_strategy='epoch',\n",
    "#     save_strategy='epoch',\n",
    "#     learning_rate=2e-5,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     num_train_epochs=3,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir='./logs',\n",
    "#     logging_steps=50,\n",
    "#     seed=SEED,\n",
    "#     report_to='none',\n",
    "#     push_to_hub=False\n",
    "# )\n",
    "\n",
    "# print('Hiperparámetros definidos.')\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./finetuned',\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,\n",
    "    eval_strategy='no',\n",
    "    save_strategy='epoch',\n",
    "    logging_steps=25,\n",
    "    logging_dir='./logs',\n",
    "    weight_decay=0.01,\n",
    "    seed=SEED,\n",
    "    report_to='none',\n",
    "    push_to_hub=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c47687c",
   "metadata": {},
   "source": [
    "## 6. Entrenar el modelo\n",
    "\n",
    "Ejecutamos el proceso de entrenamiento usando los datos tokenizados y la configuración definida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36105bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    acc = np.mean([\n",
    "        p.strip() == l.strip()\n",
    "        for p, l in zip(decoded_preds, decoded_labels)\n",
    "    ])\n",
    "\n",
    "    return {\"accuracy\": acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bc54951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "dev_dataset = Dataset.from_pandas(dev_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d0b1f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"input\"],\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        examples[\"output\"],\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60256fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 21676/21676 [00:03<00:00, 7065.90 examples/s]\n",
      "Map: 100%|██████████| 79/79 [00:00<00:00, 5265.46 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "\n",
    "dev_dataset = dev_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=dev_dataset.column_names\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d04f57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\walte\\AppData\\Local\\Temp\\ipykernel_6572\\3903211903.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c1fa12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='204' max='5420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 204/5420 29:02 < 12:29:51, 0.12 it/s, Epoch 0.07/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>13.451400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.618500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.785400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.843700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.604700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.818600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.604900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29d2f80",
   "metadata": {},
   "source": [
    "## 7. Evaluar el modelo ajustado\n",
    "\n",
    "Evaluamos el modelo fine-tuned en el conjunto de validación y mostramos métricas relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d481949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de validación\n",
    "eval_results = trainer.evaluate()\n",
    "print('Resultados de evaluación:', eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e174464c",
   "metadata": {},
   "source": [
    "## 8. Guardar el modelo fine-tuned\n",
    "\n",
    "Guardamos el modelo entrenado y el tokenizer para su uso posterior o despliegue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7157bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo y el tokenizer\n",
    "output_dir = './llama3-finetuned-final'\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(f'Modelo y tokenizer guardados en {output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9ea1b2",
   "metadata": {},
   "source": [
    "## 9. Inferencia: probar el modelo fine-tuned\n",
    "\n",
    "Ejecuta el modelo ajustado sobre ejemplos nuevos o del set de test, como se requiere en la consigna del trabajo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a8b616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de inferencia con el modelo fine-tuned\n",
    "from transformers import pipeline\n",
    "\n",
    "# Cargar modelo y tokenizer fine-tuned\n",
    "dir_finetuned = './llama3-finetuned-final'\n",
    "model = AutoModelForCausalLM.from_pretrained(dir_finetuned)\n",
    "tokenizer = AutoTokenizer.from_pretrained(dir_finetuned)\n",
    "\n",
    "# Ejemplo: usar un input del set de test o uno propio\n",
    "test_example = \"Ore ndorombyai kuri [TYPE:AFF]\"\n",
    "inputs = tokenizer(test_example, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=30)\n",
    "pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print('Input:', test_example)\n",
    "print('Predicción:', pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
